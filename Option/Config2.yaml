llm:
  # api_type: open_llm
  # base_url: 'http://0.0.0.0:30000/v1'
  # model: 'gpt-3.5-turbo'
  api_type: "openai"  # or ollama  etc.
  base_url: "https://cfcus02.opapi.win/v1"  # or forward url / other llm url
  api_key: "sk-XVBaWFFC3af98090Dc32T3BLbkFJ0Ba9481790144B1eaA6B"
  model: "TA/meta-llama/Llama-3-8b-chat-hf"


embedding:
  api_type: "hf"  # or  ollama / etc.
  base_url: "https://cfcus02.opapi.win/v1"  # or forward url / other llm url
  # api_key: "sk-XVBaWFFC3af98090Dc32T3BLbkFJ0Ba9481790144B1eaA6B"
  api_key: "dsdsd"
  model: "BAAI/bge-m3"
  dimensions: 128
  max_token_size: 8102
  embed_batch_size: 128
  embedding_func_max_async: 16
 
data_root: /mnt/data/wangshu/hcarag/ids_data # Root directory for data

# working_dir: ./test_book # Result directory for the experiment
# exp_name: test_tog # Experiment name


working_dir: /mnt/data/yingli/GraphRAG # Result directory for the experiment
exp_name: lamma8b_hipporag # Experiment name
# 